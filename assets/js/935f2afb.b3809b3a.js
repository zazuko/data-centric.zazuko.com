"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"aboutSidebar":[{"type":"link","label":"Intro","href":"/data-centric.zazuko.com/docs/about/","docId":"about/about"},{"type":"link","label":"Di\xe1taxis","href":"/data-centric.zazuko.com/docs/about/diataxis","docId":"about/diataxis"}],"rdfjsSidebar":[{"type":"link","label":"RDF/JS","href":"/data-centric.zazuko.com/docs/rdfjs/","docId":"rdfjs/rdfjs"}],"workflowsSidebar":[{"type":"link","label":"Introduction","href":"/data-centric.zazuko.com/docs/workflows/","docId":"workflows/workflows"},{"type":"category","label":"Tutorials","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Getting started","href":"/data-centric.zazuko.com/docs/workflows/tutorial/first-pipeline","docId":"workflows/tutorial/first-pipeline"}]},{"type":"category","label":"How-To","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Automate pipelines","href":"/data-centric.zazuko.com/docs/workflows/how-to/automate-pipeline","docId":"workflows/how-to/automate-pipeline"}]},{"type":"category","label":"Explanations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Pipeline Concepts","href":"/data-centric.zazuko.com/docs/workflows/explanations/pipeline","docId":"workflows/explanations/pipeline"},{"type":"link","label":"Operations","href":"/data-centric.zazuko.com/docs/workflows/explanations/operations","docId":"workflows/explanations/operations"},{"type":"link","label":"Writing valid pipelines","href":"/data-centric.zazuko.com/docs/workflows/explanations/pipeline-validity","docId":"workflows/explanations/pipeline-validity"}]}]},"docs":{"about/about":{"id":"about/about","title":"Intro","description":"These pages present various methods for building data-centric software using RDF and (mostly) JavaScript.","sidebar":"aboutSidebar"},"about/diataxis":{"id":"about/diataxis","title":"Di\xe1taxis","description":"All documentation is written according to Di\xe1taxis principles,","sidebar":"aboutSidebar"},"rdfjs/rdfjs":{"id":"rdfjs/rdfjs","title":"RDF/JS","description":"RDF/JS is a set of W3C community specifications which give developers a common denominator","sidebar":"rdfjsSidebar"},"workflows/explanations/operations":{"id":"workflows/explanations/operations","title":"Operations","description":"Obviously you want to convert your own data. To do that, barnard59 provides a bunch of default features in so called operations. To understand how you can add your own steps and pipelines, consult the barnard59 readme.","sidebar":"workflowsSidebar"},"workflows/explanations/pipeline":{"id":"workflows/explanations/pipeline","title":"Pipeline Concepts","description":"Concept","sidebar":"workflowsSidebar"},"workflows/explanations/pipeline-validity":{"id":"workflows/explanations/pipeline-validity","title":"Writing valid pipelines","description":"Step Lists","sidebar":"workflowsSidebar"},"workflows/how-to/automate-pipeline":{"id":"workflows/how-to/automate-pipeline","title":"Automate pipelines","description":"There is lots of RDF data published as one can see in the Linked Open Data Cloud Diagram. Unfortunately a lot of this data was a one-time effort by a research project or an individual and is not kept up to date. One of the design goals of barnard59 is to simplify automation so RDF data can be kept up to date with little to no effort, at least as long as the data source stays stable.","sidebar":"workflowsSidebar"},"workflows/tutorial/first-pipeline":{"id":"workflows/tutorial/first-pipeline","title":"Getting started","description":"In this tutorial we will create a simple pipeline which fetches the current time from a Web API at","sidebar":"workflowsSidebar"},"workflows/workflows":{"id":"workflows/workflows","title":"Introduction to RDF Workflows","description":"barnard59 primer","sidebar":"workflowsSidebar"}}}')}}]);